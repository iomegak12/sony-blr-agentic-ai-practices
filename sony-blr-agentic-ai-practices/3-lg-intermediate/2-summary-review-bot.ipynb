{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fe7c0c8-ffd0-4332-bde4-4ffc80cd8bb0",
   "metadata": {},
   "source": [
    "## Setup Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcee502-e847-446e-8565-e4443b38ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o\", temperature=0.5, max_tokens=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfd5d90-2f74-43d7-bc99-4caf1fcc2fb4",
   "metadata": {},
   "source": [
    "## 05.02. Engineer prompts for reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ee6170-be8e-470f-bda8-2c5a1674eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer_prompt=\"\"\"\n",
    "You are an document summarizer who can summarize a document provide to you.\n",
    "For the input provided, create a summary with less than 50 words.\n",
    "If the user has provides critique, responsed with a revised version of your previous attempts\n",
    "\"\"\"\n",
    "\n",
    "reviewer_prompt=\"\"\"\n",
    "You are a reviewer grading summaries for an article. \n",
    "Compare the user input document and generated summary.\n",
    "Check if the summary accurately reflects the contents of the document.\n",
    "Provide recommendations for improvement in less than 50 words.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a0496b-d2d6-4666-a46b-78f54df0ee13",
   "metadata": {},
   "source": [
    "## 05.03. Setup the summary-with-review Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68226bc6-06ff-4d28-9761-516790aeb378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "\n",
    "class SummaryAgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "\n",
    "class SummaryAgent:\n",
    "    \n",
    "    def __init__(self, model, summarizer_prompt, reviewer_prompt, debug=False):\n",
    "        \n",
    "        self.model=model\n",
    "        self.summarizer_prompt=summarizer_prompt\n",
    "        self.reviewer_prompt=reviewer_prompt\n",
    "        self.debug=debug\n",
    "    \n",
    "        summary_agent_graph=StateGraph(SummaryAgentState)\n",
    "        summary_agent_graph.add_node(\"summarizer\",self.generate_summary)\n",
    "        summary_agent_graph.add_node(\"reviewer\",self.review_summary)\n",
    "\n",
    "        summary_agent_graph.add_conditional_edges(\n",
    "            \"summarizer\",\n",
    "            self.should_continue,\n",
    "            {True: \"reviewer\", False: END }\n",
    "        )\n",
    "        summary_agent_graph.add_edge(\"reviewer\", \"summarizer\")\n",
    "        summary_agent_graph.set_entry_point(\"summarizer\")\n",
    "\n",
    "        #Add chat memory\n",
    "        self.memory=MemorySaver()\n",
    "        #Compile the graph\n",
    "        self.summary_agent_graph = summary_agent_graph.compile(checkpointer=self.memory)\n",
    "\n",
    "    def generate_summary(self, state:SummaryAgentState):\n",
    "        messages=state[\"messages\"]\n",
    "\n",
    "        #Prepend summarizer system prompt to messages\n",
    "        messages = [SystemMessage(content=self.summarizer_prompt)] + messages\n",
    "        \n",
    "        #invoke the summarizer with the message history\n",
    "        result = self.model.invoke(messages)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"==============\\n Generator returned output : {result.content}\")\n",
    "        return { \"messages\":[result] }\n",
    "\n",
    "    def review_summary(self, state:SummaryAgentState):\n",
    "        messages=state[\"messages\"]\n",
    "\n",
    "        #Prepend Reviewer system prompt to messages\n",
    "        messages = [SystemMessage(content=self.reviewer_prompt)] + messages\n",
    "        \n",
    "        #invoke the reviewer with the message history\n",
    "        result = self.model.invoke(messages)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"*************\\n Reviewer returned output : {result.content}\")\n",
    "        return { \"messages\":[result] }\n",
    "\n",
    "    def should_continue(self, state:SummaryAgentState):\n",
    "\n",
    "        total_reviews = len(state[\"messages\"]) / 2\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"Iteration number : { total_reviews }\")\n",
    "\n",
    "        #Return if 2 iterations are completed. Each iteration has 2 messages\n",
    "        if len(state[\"messages\"]) > 4:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07a1cfd-e482-4c29-a511-c2c4e710de76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "#Setup the summary chatbot\n",
    "summary_chatbot = SummaryAgent(model, \n",
    "                               summarizer_prompt, \n",
    "                               reviewer_prompt,\n",
    "                               debug=True)\n",
    "\n",
    "Image(summary_chatbot.summary_agent_graph.get_graph().draw_mermaid_png())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff589c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Input file for execution\n",
    "# Load, chunk and index the contents of the pdf.\n",
    "loader=PyPDFLoader(\"./data/EcoSprint_Specification_Document.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "#Pick the first page of the doc as content\n",
    "source_content=docs[0].page_content.replace(\"\\n\",\" \")\n",
    "print(f\"Input :==============\\n {source_content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702dd0d5-642b-4790-a798-93779944cb1a",
   "metadata": {},
   "source": [
    "## 05.05. Execute the summary-with-review chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7dced1-1af4-4f92-932b-d8152381fac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "#Execute a single request with debug ON\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "messages=[HumanMessage(content=source_content)]\n",
    "result=summary_chatbot.summary_agent_graph.invoke({\"messages\":messages},config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18124d5-b098-4b25-9d95-151dcf0cf3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take user feedback on the summary through a chatbot\n",
    "summary_chatbot = SummaryAgent(model, \n",
    "                               summarizer_prompt, \n",
    "                               reviewer_prompt,\n",
    "                               debug=False)\n",
    "\n",
    "\n",
    "user_inputs = [\n",
    "    source_content,\n",
    "    \"Can you rewrite the review by focusing more on the specifications?\",\n",
    "    \"Can you remove details about the touchscreen?\"\n",
    "]\n",
    "\n",
    "#Create a new thread\n",
    "config = {\"configurable\": {\"thread_id\": \"thread-summarizer\"}}\n",
    "\n",
    "#Given the number of iterations, this will take a long time.\n",
    "for input in user_inputs:\n",
    "    print(f\"----------------------------------------\\nUSER : {input}\")\n",
    "    #Format the user message\n",
    "    user_message = {\"messages\":[HumanMessage(input)]}\n",
    "    #Get response from the agent\n",
    "    ai_response = summary_chatbot.summary_agent_graph.invoke(user_message,config=config)\n",
    "    #Print the response\n",
    "    print(f\"\\nAGENT : {ai_response['messages'][-1].content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
